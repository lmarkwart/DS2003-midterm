{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "debd70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c33552f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mongodb+srv://laurenmarkwart:Langley123@policekillings.jeczt7v.mongodb.net\n"
     ]
    }
   ],
   "source": [
    "host_name = \"localhost\"\n",
    "ports = {\"mongo\" : 27017, \"mysql\" : 3306}\n",
    "\n",
    "user_id = \"lmarkwart\"\n",
    "pwd = \"Password123\"\n",
    "\n",
    "atlas_cluster_name = \"policekillings\"\n",
    "atlas_user_name = \"laurenmarkwart\"\n",
    "atlas_password = \"Langley123\"\n",
    "\n",
    "conn_str = {\"local\" : f\"mongodb://localhost:27017/\",\n",
    "    \"atlas\" : f\"mongodb+srv://{atlas_user_name}:{atlas_password}@{atlas_cluster_name}.jeczt7v.mongodb.net\"\n",
    "}\n",
    "print(conn_str['atlas'])\n",
    "src_dbname = \"police_killings\"\n",
    "dst_dbname = \"police_killings2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66dcd754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_dataframe(user_id, pwd, host_name, db_name, sql_query):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    conn = sqlEngine.connect()\n",
    "    dframe = pd.read_sql(sql_query, conn);\n",
    "    conn.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def get_mongo_dataframe(user_id, pwd, host_name, port, db_name, collection, query):\n",
    "    '''Create a connection to MongoDB, with or without authentication credentials'''\n",
    "    if user_id and pwd:\n",
    "        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db_name)\n",
    "        client = pymongo.MongoClient(mongo_uri)\n",
    "    else:\n",
    "        conn_str = f\"mongodb://{host_name}:{port}/\"\n",
    "        client = pymongo.MongoClient(conn_str)\n",
    "    \n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    client.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def set_dataframe(user_id, pwd, host_name, db_name, df, table_name, pk_column, db_operation):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        sqlEngine.execute(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\")\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "147df36a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Student\\\\OneDrive\\\\Documents\\\\DS-2002-002-main\\\\03-NoSQL\\\\Midterm-project\\\\victims.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m json_files:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#db.drop_collection(file)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     json_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, json_files[file])\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m openfile:\n\u001b[0;32m     20\u001b[0m         json_object \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(openfile)\n\u001b[0;32m     21\u001b[0m         file \u001b[38;5;241m=\u001b[39m db[file]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Student\\\\OneDrive\\\\Documents\\\\DS-2002-002-main\\\\03-NoSQL\\\\Midterm-project\\\\victims.json'"
     ]
    }
   ],
   "source": [
    "#print(conn_str['atlas'])\n",
    "\n",
    "client = pymongo.MongoClient(conn_str[\"atlas\"])\n",
    "db = client[src_dbname]\n",
    "\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'Midterm-project')\n",
    "\n",
    "json_files = {\"victim\" : 'victims.json',\n",
    "              \"location\" : 'location.json',\n",
    "              \"date\" : 'dates.json',\n",
    "              \"incident_facts\" : 'cause.json',\n",
    "              \"population_facts\" : 'population.json'\n",
    "             }\n",
    "\n",
    "for file in json_files:\n",
    "    #db.drop_collection(file)\n",
    "    json_file = os.path.join(data_dir, json_files[file])\n",
    "    with open(json_file, 'r') as openfile:\n",
    "        json_object = json.load(openfile)\n",
    "        file = db[file]\n",
    "        result = file.insert_many(json_object)\n",
    "        #print(f\"{file} was successfully loaded.\")\n",
    "\n",
    "        \n",
    "client.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6bae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_victim = \"SELECT * FROM police_killings.victim;\"\n",
    "df_victim = get_dataframe(user_id, pwd, host_name, src_dbname, sql_victim)\n",
    "df_victim.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_date = \"SELECT * FROM police_killings.date;\"\n",
    "df_date = get_dataframe(user_id, pwd, host_name, src_dbname, sql_date)\n",
    "df_date.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_location = \"SELECT * FROM police_killings.location;\"\n",
    "df_location = get_dataframe(user_id, pwd, host_name, src_dbname, sql_location)\n",
    "df_location.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_ftc = \"SELECT * FROM police_killings.fact_table_complete;\"\n",
    "df_ftc = get_dataframe(user_id, pwd, host_name, src_dbname, sql_ftc)\n",
    "df_ftc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b399dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {}\n",
    "port = ports[\"mongo\"]\n",
    "collection = \"victim\"\n",
    "\n",
    "df_victim = get_mongo_dataframe(None, None, host_name, port, src_dbname, collection, query)\n",
    "df_victim.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df_victim\n",
    "table_name = 'victim'\n",
    "primary_key = 'victim_ID'\n",
    "db_operation = \"insert\"\n",
    "\n",
    "set_dataframe(user_id, pwd, host_name, dst_dbname, dataframe, table_name, primary_key, db_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a1603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_victim = \"SELECT * FROM northwind_dw2.dim_suppliers;\"\n",
    "df_dim_suppliers = get_sql_dataframe(user_id, pwd, host_name, dst_dbname, sql_suppliers)\n",
    "df_dim_suppliers.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
